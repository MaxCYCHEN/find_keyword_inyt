{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba296a1-e237-4b02-b8cf-cbbb38e06583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\find_keyword_inyt\\Lib\\site-packages\\whisper\\timing.py:57: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\find_keyword_inyt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pytube import YouTube\n",
    "import librosa\n",
    "import soundfile\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "#from googleapiclient.discovery import build\n",
    "import whisper_timestamped as whisper\n",
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173db6d9",
   "metadata": {},
   "source": [
    "## 1. Download the Youtube's audios from a `yt_dl_list.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd78a72",
   "metadata": {},
   "source": [
    "- 1. Get the keyword video link from this website: https://youglish.com/pronounce/reset/english?\n",
    "- 2. Copy all the Youtube's link which exist the keyword to `yt_dl_list.txt`\n",
    "- 3. Execute the below block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56fcd05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to see with sound - Jacques S. Abramowicz 316 TED-Ed\n",
      "Finish!ding… 100.00\n",
      "Download 1 audio!\n",
      "How Do Insect Eyes Work? | Compound Eyes | Amazing Animal Senses | SciShow Kids 291 SciShow Kids\n",
      "Finish!ding… 100.00\n",
      "Download 2 audio!\n",
      "Meat-Ghetti & Spag-Balls from American Dad | Botched by Babish 1119 Babish Culinary Universe\n",
      "Finish!ding… 100.00\n",
      "Download 3 audio!\n",
      "The IPCC mitigation report explained in less than 8 minutes feat. @ClimateAdam 462 zentouro\n",
      "Finish!ding… 100.00\n",
      "Download 4 audio!\n",
      "How bumble bees inspired a network of tiny museums | Amanda Schochet 668 TED\n",
      "Finish!ding… 100.00\n",
      "Download 5 audio!\n",
      "Finish all download 5.\n"
     ]
    }
   ],
   "source": [
    "def onProgress(stream, chunk, remains):\n",
    "    total = stream.filesize                     # 取得完整尺寸\n",
    "    percent = (total-remains) / total * 100     # 減去剩餘尺寸 ( 剩餘尺寸會抓取存取的檔案大小 )\n",
    "    print(f'downloading… {percent:05.2f}', end='\\r')  # 顯示進度，\\r 表示不換行，在同一行更新\n",
    "\n",
    "# Download audio from YouTube video and convert to WAV format\n",
    "def download_youtube_audio_pytube(video_url):\n",
    "    # Extract video ID from the video URL\n",
    "    if \"youtu.be\" in video_url:\n",
    "        video_id = video_url.split(\"youtu.be/\")[1]\n",
    "    elif \"watch?v=\" in video_url:    \n",
    "        video_id = video_url.split(\"watch?v=\")[1]\n",
    "    else:\n",
    "        print(\"The link is error: {}\".format(video_url)) \n",
    "\n",
    "    mp3_audio_name = os.path.join('download_raw', (video_id + r'.mp3'))\n",
    "    wav_audio_name = os.path.join('download_raw', (video_id + r'.wav'))\n",
    "    #print(mp3_audio_name)\n",
    "    \n",
    "    yt = YouTube(video_url, on_progress_callback=onProgress)\n",
    "    print(yt.title, yt.length, yt.author) # 影片標題, 影片長度 ( 秒 ), 影片作者 \n",
    "    \n",
    "    yt.streams.filter().get_audio_only().download(filename=mp3_audio_name)\n",
    "    \n",
    "    # Transfer to wav format, because the next process need wav pcm format.\n",
    "    sound = AudioSegment.from_file(mp3_audio_name)\n",
    "    sound.export(wav_audio_name, format=\"wav\")\n",
    "    \n",
    "    print('Finish!')\n",
    "    os.remove(mp3_audio_name)\n",
    "    \n",
    "    return wav_audio_name\n",
    "\n",
    "# Start to loop the line in yt list file\n",
    "dl_count = 0\n",
    "with open('yt_dl_list.txt') as f:\n",
    "    for line in f:\n",
    "       dl_count += 1 \n",
    "       download_youtube_audio_pytube(line.strip())\n",
    "       print(\"Download {} audio!\".format(dl_count)) \n",
    "print(\"Finish all download {}.\".format(dl_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b52cb7",
   "metadata": {},
   "source": [
    "## 2. Find & Crop the keyword wav file.\n",
    "- Update the `search_pattern` to the keyword you want. \n",
    "- This section will read the lines in `yt_dl_list.txt` and find the downloaded audio with its transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90ea4b1-1092-4ad4-b24c-ff1e8f9ea4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the search pattern for the desired paragraph\n",
    "search_pattern = r\"zoom in\"\n",
    "\n",
    "# Set the path to the ffmpeg binary (required by SpeechRecognition)\n",
    "#ffmpeg_path = \"C:\\\\Users\\\\CYCHEN38\\\\MICRO_ML\\\\ffmpeg-2023-06-27-git-9b6d191a66-essentials_build\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5d4aea8-e659-47bb-9429-bb7a625ddad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a SpeechRecognition Recognizer instance\n",
    "# recognizer = sr.Recognizer()\n",
    "dict_log = {} # The log for transcribe_cut_audio & cut_audio_segment\n",
    "\n",
    "def wave_converter(filename, origin_sr, origin_data, resampled_sr=16000, prefix=\"resampled_\", mix2mono = True):\n",
    "\n",
    "    '''\n",
    "    Resample WAV soundfile to a different sample rate.\n",
    "    \n",
    "        Input: original sound file\n",
    "        Output: resampled sound file\n",
    "        Parameters: \n",
    "            - name of the file to be converted, \n",
    "            - destination sample rate, default = 16kHz\n",
    "            - prefix to identify resampled files\n",
    "            - mix to mono channel, default = False (leave as-is)\n",
    "            \n",
    "        Notes: for simplicity it needs to be run in the folder with the files we are converting\n",
    "    '''    \n",
    "    \n",
    "    resampled_file = prefix + filename + '.wav'\n",
    "    origin_type = origin_data.dtype\n",
    "    \n",
    "    # transpose array to librosa shape\n",
    "    resampled_data = librosa.resample(origin_data.T.astype('float'), orig_sr = origin_sr,  target_sr = resampled_sr) \n",
    "    \n",
    "    if mix2mono == True:\n",
    "        resampled_data = librosa.to_mono(resampled_data)\n",
    "    if origin_type != 'int16':\n",
    "        print(\"Warning: the data type is changed from {} to int16\".format(origin_type))\n",
    "        resampled_data = resampled_data.T.astype('int16') # transpose back to scipy.io.wavfile shape\n",
    "    else:\n",
    "        resampled_data = resampled_data.T.astype(origin_type) # transpose back to scipy.io.wavfile shape\n",
    "    \n",
    "    write(resampled_file, resampled_sr, resampled_data)\n",
    "    #print('Resampled wavefile saved to {}'.format(resampled_file))\n",
    "\n",
    "# Transcribe audio and grep desired paragraph\n",
    "def transcribe_cut_audio(audio_file, search_pattern, video_id, dict_single_log, ma_cut):\n",
    "    #----------------------\n",
    "    # Basing on the YT transcript to cut the section of search_pattern to a small audio first.\n",
    "    #----------------------\n",
    "    t_s = 0\n",
    "    t_e = 0\n",
    "    buf_time = 5 # bcs the recognize_google need a long enough audio.\n",
    "    \n",
    "    rate, data = read(audio_file)       \n",
    "    # print(rate, len(data))\n",
    "    \n",
    "    # assigning srt with the list of dictionaries obtained by the get_transcript() function\n",
    "    try:\n",
    "       srt = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "    except:\n",
    "       srt = YouTubeTranscriptApi.get_transcript(video_id, languages=['en-US']) \n",
    "    \n",
    "    for dict_text in srt:\n",
    "        search_pattern = r'\\b{}\\b'.format(search_pattern)\n",
    "        #match = re.findall(pattern, string)\n",
    "        match = re.search(search_pattern, dict_text['text'], re.IGNORECASE)\n",
    "        if match:\n",
    "            t_s = (int)(dict_text['start']) * rate\n",
    "            t_e = (int)(dict_text['start'] + dict_text['duration']) * rate\n",
    "            #print('\\n')\n",
    "            #print('Found search_pattern section:')\n",
    "            #print(dict_text['text'], t_s, t_e)\n",
    "            #print('\\n')\n",
    "            \n",
    "    t_s = t_s - rate * buf_time \n",
    "    t_e = t_e + rate * buf_time\n",
    "    dict_single_log['cut_t_s_idx'] = t_s\n",
    "    dict_single_log['cut_t_e_idx'] = t_e\n",
    "    # write(\"{}.wav\".format('tempcut'), rate, data[t_s:t_e])\n",
    "    \n",
    "    #----------------------\n",
    "    # Convert to 16khz, mono, int16\n",
    "    #----------------------\n",
    "    wave_converter('cut', rate, data[t_s: t_e])\n",
    "\n",
    "    #----------------------\n",
    "    # cut_audio_segment\n",
    "    #----------------------\n",
    "    keyword_dict = cut_audio_segment(video_id, dict_single_log, ma_cut)\n",
    "    \n",
    "    return keyword_dict\n",
    "\n",
    "def cut_audio_segment(video_id, dict_single_log, ma_cut):    \n",
    "   audio = whisper.load_audio('resampled_cut.wav')\n",
    "   model = whisper.load_model(\"base\")\n",
    "   result = whisper.transcribe(model, audio, language=\"en\")\n",
    "   #print(json.dumps(result, indent = 2, ensure_ascii = False))\n",
    "    \n",
    "   # check if search_pattern is 2 word keyword.\n",
    "   if ' ' in search_pattern:\n",
    "       search_pattern_0 = search_pattern.split(' ')[0]\n",
    "       search_pattern_1 = search_pattern.split(' ')[1]\n",
    "        \n",
    "       # Find the match keyword and its start&end time\n",
    "       t_s = 0\n",
    "       t_e = 0\n",
    "       for i, segment in enumerate(result['segments']):\n",
    "         #print(segment['words'])\n",
    "         for j, word in enumerate(segment['words']):\n",
    "             if (search_pattern_0 in word['text'].lower())and(search_pattern_1 in segment['words'][(j+1)]['text'].lower()):\n",
    "               # Combine the 2 set into 1 \n",
    "               t_s = word['start']\n",
    "               t_e = segment['words'][(j+1)]['end']\n",
    "               dict_single_log['key_t_s'] = t_s\n",
    "               dict_single_log['key_t_e'] = t_e\n",
    "               print(\"keyword start time: {}, end time: {}\".format(t_s, t_e))\n",
    "               break\n",
    "         if t_e != 0:\n",
    "           break\n",
    "   else:\n",
    "       # Find the match keyword and its start&end time\n",
    "       t_s = 0\n",
    "       t_e = 0\n",
    "       for i, segment in enumerate(result['segments']):\n",
    "         #print(segment['words'])\n",
    "         for j, word in enumerate(segment['words']):\n",
    "             if search_pattern in word['text'].lower():\n",
    "               t_s = word['start']\n",
    "               t_e = word['end']\n",
    "               dict_single_log['key_t_s'] = t_s\n",
    "               dict_single_log['key_t_e'] = t_e\n",
    "               print(\"keyword start time: {}, end time: {}\".format(t_s, t_e))\n",
    "               break\n",
    "         if t_e != 0:\n",
    "           break\n",
    "   \n",
    "   # The PCM array's idx           \n",
    "   rate, data = read('resampled_cut.wav')\n",
    "   t_s = (int)(np.floor((t_s) * rate)) \n",
    "   t_e = (int)(np.ceil((t_e) * rate))\n",
    "   \n",
    "   # mean & std, so far no use.\n",
    "   real_data = np.absolute(data[t_s : t_e])\n",
    "   mean_d_win = real_data.mean()\n",
    "   std_win    = real_data.std()\n",
    "   #print(\"keyword's mean & std: {}, {}\".format(mean_d_win, std_win))\n",
    "   \n",
    "   # Add the reduant before & after to a 1 second wav\n",
    "   tt_buf = (int)((rate*1 - (t_e - t_s))/2)\n",
    "   t_s -= tt_buf\n",
    "   t_e += tt_buf\n",
    "   dict_single_log['key_t_s_adj_idx'] = t_s\n",
    "   dict_single_log['key_t_e_adj_idx'] = t_e\n",
    "   #print(\"array idx of final keyword wav, start, end: {}, {} \".format(t_s, t_e))\n",
    "   \n",
    "   # Add zero\n",
    "   #zero_buf = np.zeros((tt_buf), dtype = int)\n",
    "   #data = np.concatenate((zero_buf, data[t_s: t_e], zero_buf), axis=None)\n",
    "   #print(data.size)\n",
    "   \n",
    "   # if ma_cut has value, manually cut for minor adjustment\n",
    "   if ma_cut:\n",
    "       t_s += (int)(ma_cut['r_shift'] * rate)\n",
    "       t_e += (int)(ma_cut['r_shift'] * rate)\n",
    "       dict_single_log['key_t_s_adj_manu'] = t_s\n",
    "       dict_single_log['key_t_e_adj_manu'] = t_e\n",
    "       print('manually cut for minor adjustment! {}, {}'.format(t_s, t_e))\n",
    "   \n",
    "   # Boundary conditions\n",
    "   if  t_s < 0:\n",
    "       t_s = 0\n",
    "       t_e = (int)(rate)\n",
    "   elif t_e > len(data) :\n",
    "       t_e = len(data)\n",
    "       t_s =  (int)(len(data) - rate)  \n",
    "   \n",
    "   output_file = video_id + '_nohash_0.wav'\n",
    "   write(os.path.join('keyword', output_file), rate, data[t_s: t_e])\n",
    "   \n",
    "   return dict_single_log   \n",
    "\n",
    "def main():\n",
    "    \n",
    "    total_line = 0\n",
    "    with open('yt_dl_list.txt') as f:\n",
    "        for line in f:\n",
    "           total_line += 1\n",
    "           \n",
    "    with tqdm(total=total_line) as pbar:\n",
    "        pbar.set_description('Processing segement:')\n",
    "        \n",
    "        try:       \n",
    "            # Start to loop the line in yt list file\n",
    "            dl_count = 0\n",
    "            with open('yt_dl_list.txt') as f:\n",
    "                for line in f:\n",
    "                    \n",
    "                   dict_single_log = {} \n",
    "                   dl_count += 1 \n",
    "                   video_url = line.strip()\n",
    "                   \n",
    "                   # Extract video ID from the video URL\n",
    "                   if \"youtu.be\" in video_url:\n",
    "                       video_id = video_url.split(\"youtu.be/\")[1]\n",
    "                   elif \"watch?v=\" in video_url:    \n",
    "                       video_id = video_url.split(\"watch?v=\")[1]\n",
    "                   else:\n",
    "                       print(\"The link is error: {}\".format(video_url))\n",
    "                       \n",
    "                   audio_file = os.path.join('download_raw', (video_id + r'.wav'))     \n",
    "            \n",
    "                   if audio_file:\n",
    "                       # Transcribe audio and grep desired paragraph\n",
    "                       dict_single_log = transcribe_cut_audio(audio_file, search_pattern, video_id, dict_single_log, {})\n",
    "                       # print(\"Done {}!\".format(dl_count))\n",
    "                   else:\n",
    "                       print(\"Error downloading audio.\")\n",
    "                   \n",
    "                   dict_log[video_id] = dict_single_log\n",
    "                   pbar.update(1)\n",
    "        except:\n",
    "            print(\"The yt_dl_list.txt or func transcribe_cut_audio has issue!\")\n",
    "            \n",
    "        finally:\n",
    "            with open(\"cut_log.json\", \"w\") as outfile:\n",
    "                json.dump(dict_log, outfile)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36be2c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing segement::   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1400 [00:00<?, ?frames/s]\u001b[A\n",
      "100%|██████████| 1400/1400 [00:01<00:00, 1037.35frames/s]\u001b[A\n",
      "Processing segement::  20%|██        | 1/5 [00:03<00:15,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 6.54, end time: 7.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1300 [00:00<?, ?frames/s]\u001b[A\n",
      "100%|██████████| 1300/1300 [00:01<00:00, 914.72frames/s]\u001b[A\n",
      "Processing segement::  40%|████      | 2/5 [00:06<00:09,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 7.26, end time: 7.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1300 [00:00<?, ?frames/s]\u001b[A\n",
      "100%|██████████| 1300/1300 [00:01<00:00, 876.79frames/s]\u001b[A\n",
      "Processing segement::  60%|██████    | 3/5 [00:09<00:06,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 4.86, end time: 5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?frames/s]\u001b[A\n",
      "100%|██████████| 1200/1200 [00:01<00:00, 626.05frames/s]\u001b[A\n",
      "Processing segement::  80%|████████  | 4/5 [00:12<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 5.72, end time: 6.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1300 [00:00<?, ?frames/s]\u001b[A\n",
      "100%|██████████| 1300/1300 [00:01<00:00, 923.69frames/s]\u001b[A\n",
      "Processing segement:: 100%|██████████| 5/5 [00:15<00:00,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 7.2, end time: 7.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42361037-3ff9-470b-9e09-4721cbc981c0",
   "metadata": {},
   "source": [
    "## 3. Check the format of wav file\n",
    "- Just make sure the format of keyword wav is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f28e50f-1245-4782-a795-9d5b05321217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 16000 Hz\n",
      "Data type: int16\n",
      "Data Seconds: 1.0 s\n",
      "Number of channels: 1\n",
      "Data length: 16000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rate, data = read('keyword/4JLNb8-LOB0_nohash_0.wav')\n",
    "\n",
    "ch = 1 if data.size/data.shape[0]==1 else 2\n",
    "\n",
    "\n",
    "print(\"Sample rate: {} Hz\".format(rate))\n",
    "print(\"Data type: {}\".format(data.dtype))\n",
    "print(\"Data Seconds: {} s\".format(data.shape[0]/rate))\n",
    "print(\"Number of channels: {}\".format(ch))\n",
    "print(\"Data length: {}\".format(len(data)))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f979b1c",
   "metadata": {},
   "source": [
    "## 4. Minor adjustment the 1(s) window of keyword manually.\n",
    "- If some keyword wavs have other words overlap, please manually shift the windows.\n",
    "- Update `video_url` and `Right_Shift_Time` upon your choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d5e9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = 'https://youtu.be/4JLNb8-LOB0'\n",
    "Right_Shift_Time = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "083c28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:01<00:00, 1008.89frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword start time: 6.54, end time: 7.18\n",
      "manually cut for minor adjustment! 104160, 120160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ma_cut = {}\n",
    "ma_cut['r_shift'] = Right_Shift_Time # The unit is (s)\n",
    "\n",
    "\n",
    "    \n",
    "# Extract video ID from the video URL\n",
    "if \"youtu.be\" in video_url:\n",
    "    video_id = video_url.split(\"youtu.be/\")[1]\n",
    "elif \"watch?v=\" in video_url:    \n",
    "    video_id = video_url.split(\"watch?v=\")[1]\n",
    "else:\n",
    "    print(\"The link is error: {}\".format(video_url))\n",
    "    \n",
    "audio_file = os.path.join('download_raw', (video_id + r'.wav'))\n",
    "\n",
    "if audio_file:\n",
    "    # Transcribe audio and grep desired paragraph\n",
    "    dict_single_log = transcribe_cut_audio(audio_file, search_pattern, video_id, {}, ma_cut)\n",
    "    # print(\"Done {}!\".format(dl_count))\n",
    "else:\n",
    "    print(\"Error downloading audio.\")\n",
    "\n",
    "\n",
    "# Update log\n",
    "with open('cut_log.json', 'r') as openfile:\n",
    "    # Reading from json file\n",
    "    cut_log_json = json.load(openfile)\n",
    "\n",
    "cut_log_json[video_id]['r_shift'] = Right_Shift_Time  \n",
    "    \n",
    "with open(\"cut_log.json\", \"w\") as outfile:\n",
    "    json.dump(cut_log_json, outfile)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d04fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7bd32a645e2bc9137254e4f099fe8750e15505642a9446b95e0f50a07928dac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
